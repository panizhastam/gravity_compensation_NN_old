{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Creating a MLP regression model with PyTorch\n",
    "The first step is to import all the required dependencies. Then, we will use a Multilayer Perceptron based model, which is essentially a stack of layers containing neurons that can be trained.\n",
    "We also have to ensure that the dataset is prepared into a DataLoader, which ensures that data is shuffled and batched appropriately.\n",
    "Then, we pick a loss function and initialize it. We also init the model and the optimizer (Adam).\n",
    "Finally, we create the training loop, which effectively contains the high-level training process captured in code."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import MyData\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we read the csv data and try to print the header"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Elbow_theta  ShFE_theta  ShAA_theta  Elbow_tao  ShFE_tao  ShAA_tao\n",
      "0          0.0         0.0         0.0   0.000000       0.0       0.0\n",
      "1          0.0         0.0         0.0   0.000018       0.0       0.0\n",
      "2          0.0         0.0         0.0   0.000074       0.0       0.0\n",
      "3          0.0         0.0         0.0   0.000166       0.0       0.0\n",
      "4          0.0         0.0         0.0   0.000294       0.0       0.0\n",
      "(8729, 6)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/alldata_up.csv')\n",
    "print(df.head())\n",
    "print(df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "splitting the data into train and test. By that, I mean taking out the labels which we want to predict. Here, the labels are Elbow_tao, ShFE_tao, and ShAA_tao and the features are the rest."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "   Elbow_tao  ShFE_tao  ShAA_tao\n0   0.000000       0.0       0.0\n1   0.000018       0.0       0.0\n2   0.000074       0.0       0.0\n3   0.000166       0.0       0.0\n4   0.000294       0.0       0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Elbow_tao</th>\n      <th>ShFE_tao</th>\n      <th>ShAA_tao</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000018</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000074</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000166</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000294</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df[['Elbow_tao','ShFE_tao','ShAA_tao']]\n",
    "features = df.drop(['Elbow_tao','ShFE_tao','ShAA_tao'], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we split the data into train and test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "      Elbow_tao  ShFE_tao  ShAA_tao\n",
      "5089     0.0000   0.00000   1.47520\n",
      "6749     1.3824   3.33890   0.58802\n",
      "1675     0.0000   0.12017   0.00000\n",
      "8078     3.7831   5.82180   1.98150\n",
      "1773     0.0000   0.65975   0.00000\n",
      "(6983, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(labels, features,test_size=0.2)\n",
    "\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train.head())\n",
    "print(X_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m dataup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msplit\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandn(\u001B[43mdataup\u001B[49m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      2\u001B[0m datadown[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msplit\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandn(datadown\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      4\u001B[0m msk_up \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;28mlen\u001B[39m(dataup)) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.8\u001B[39m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dataup' is not defined"
     ]
    }
   ],
   "source": [
    "# dataup['split'] = np.random.randn(dataup.shape[0], 1)\n",
    "# datadown['split'] = np.random.randn(datadown.shape[0], 1)\n",
    "#\n",
    "# msk_up = np.random.rand(len(dataup)) <= 0.8\n",
    "# msk_down = np.random.rand(len(datadown)) <= 0.8\n",
    "#\n",
    "# up_train = dataup[msk_up]\n",
    "# up_test = dataup[~msk_up]\n",
    "#\n",
    "# down_train = datadown[msk_down]\n",
    "# down_test = datadown[~msk_down]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "normalizing the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# personally I don't think that its needed but here is the way:\n",
    "# d = preprocessing.normalize(dataup, axis=0)\n",
    "# scaled_df = pd.DataFrame(d, columns=names)\n",
    "# scaled_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Converting pandas Dataframe to Pytorch Tensor type\n",
    "** for now I will only work on dataup **"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\SoftExo\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SoftExo\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SoftExo\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__len__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     11\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatalist\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m---> 13\u001B[0m train_Set \u001B[38;5;241m=\u001B[39m \u001B[43mDataUpDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m trainloader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader( dataset \u001B[38;5;241m=\u001B[39m train_Set , batch_size\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m64\u001B[39m , shuffle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "Cell \u001B[1;32mIn[6], line 4\u001B[0m, in \u001B[0;36mDataUpDataset.__init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m      3\u001B[0m     train \u001B[38;5;241m=\u001B[39m up_train\n\u001B[1;32m----> 4\u001B[0m     train_labels \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m      5\u001B[0m     train \u001B[38;5;241m=\u001B[39m train\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m,axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m42000\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m28\u001B[39m,\u001B[38;5;241m28\u001B[39m)\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatalist \u001B[38;5;241m=\u001B[39m train\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SoftExo\\lib\\site-packages\\pandas\\core\\frame.py:3804\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3804\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3806\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SoftExo\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'label'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
